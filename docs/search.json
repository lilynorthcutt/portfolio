[
  {
    "objectID": "portfolio/index.html",
    "href": "portfolio/index.html",
    "title": "Projects",
    "section": "",
    "text": "A Computational Analysis of Hate Speech Across Reddit - Large Language Models\n\n\n\n\n\n\nPython\n\n\nML\n\n\nNLP\n\n\nLLM\n\n\n\n\n\n\n\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nGeologic Magmatic Migration Exploration Through Age Prediction\n\n\n\n\n\n\nPython\n\n\nGIS\n\n\nShiny\n\n\nEDA\n\n\nML\n\n\n\nDevelopping novel ML methods for magamtic migration predictions\n\n\n\n\n\nJul 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHeart Disease Indicators by Sex\n\n\n\n\n\n\nEDA\n\n\nHealthcare\n\n\nR\n\n\nML\n\n\n\n\n\n\n\n\n\nJul 18, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "portfolio/projects/sierraNevadaAge/writeup.html",
    "href": "portfolio/projects/sierraNevadaAge/writeup.html",
    "title": "Geologic Magmatic Migration Exploration Through Age Prediction",
    "section": "",
    "text": "Access the interactive dashboard of the data and predictions here! (addition of predictions coming soon)\nAccess the notebook for the full code and predictions on github !"
  },
  {
    "objectID": "portfolio/projects/sierraNevadaAge/writeup.html#introduction",
    "href": "portfolio/projects/sierraNevadaAge/writeup.html#introduction",
    "title": "Geologic Magmatic Migration Exploration Through Age Prediction",
    "section": "Introduction",
    "text": "Introduction\nMagmatism plays a key role in mountain formation, as ascending magmas add mass and volume to the Earth’s surface and subsurface. However, the causes and rates of magma movement remain largely unknown, necessitating a deeper understanding of these processes. The mountains and canyons in the Sierra Nevadas are formed from granitic rocks, which originated from molten rock that cooled far beneath the Earth’s surface. By examining the geologic ages within this area, we can gain insights into the age of the rocks at various locations and understand the magmatic migration and processes that created them.\nThe current data in the Sierra Nevadas does not uniformly cover the area, making it unrepresentative of the entire region. This is a common problem in geology, as uniformly collecting samples across a region is often impractical due to constraints such as time, resources, coverage area, or sample accessibility. Therefore, there is a need for novel methods to mitigate sampling bias and use geologic age samples to predict uniform coverage of an area.\nKey Project Goals The key goals this project aims to address are the following:\n\nDevelop novel machine learning (ML) methods to fill gaps in geologic maps by predicting undated rock ages.\nApply the results from the model to predict undated rock ages, providing a less biased view of magmatic migration.\nBuild Interactive Visualizations for researchers and curious minds to view and explore the data and predictions.\n\nThis project was done with python for all data cleaning, model training/evaluation, and predictions, and R for interactive visualizations in Shiny. The full code is extensive, so some parts are omitted here for brevity. Please refer to the link at the top to view the notebook with the entire code.\nLet’s begin!"
  },
  {
    "objectID": "portfolio/projects/sierraNevadaAge/writeup.html#preprocessing",
    "href": "portfolio/projects/sierraNevadaAge/writeup.html#preprocessing",
    "title": "Geologic Magmatic Migration Exploration Through Age Prediction",
    "section": "Preprocessing",
    "text": "Preprocessing\nWe have two data types: a csv file, and shapefiles. The csv file contains ages at specific locations, while the shapefiles contain a boundary of interest and polynomials with their geologic period.\n\nLoad Data\n\n# Read in CSV file\ncsv_file_path = \"Data/raw/attia_CentralSierraCretaceousIntrusionsGeochronologyData_forLily12082023.xlsx\"\ndf_ages_raw = pd.read_excel(csv_file_path, sheet_name =  'CentralSierraNevada Rock Ages')\n\ndf_ages_raw.head(5)\n\n\n\n\n\n\n\n\nAnalysisName\nOriginalName\nAge\nUncertainty\nReference\nMineral\nMethod\nRockType\nLithology\nUnit\nGroup\nEasting\nNorthing\nDatum\nDataComment\n\n\n\n\n0\nEL16-525\nNaN\n96.1\n0.8\nArdill et al., 2018\nZircon\nspot analyses\nPlutonic\ngranodiorite\nEllery Lake granodiorite\nunassigned, Tioga Pass\n304057\n4200841\nNAD27 11S\nNaN\n\n\n1\nHH16-522\nNaN\n96.4\n1.1\nArdill et al., 2018\nZircon\nspot analyses\nPlutonic\nporphyritic granodiorite\nporphyritic granodiorite of Lake Vernon\nJack Main Canyon intrusive suite\n258103\n4209586\nNAD27 11S\nNaN\n\n\n2\nTIOGA\nNaN\n101.0\n1.5\nArdill et al., 2018\nZircon\nspot analyses\nPlutonic\nmonzodiorite\nTioga Lake monzodiorite\nTioga Pass hypabyssal complex\n301629\n4200112\nNAD27 11S\nNaN\n\n\n3\nGP-2\nNaN\n102.2\n1.0\nArdill et al., 2018\nZircon\nspot analyses\nPlutonic\ngranodiorite\nIllouette Creek granodiorite\nBuena Vista Crest intrusive suite\n269559\n4172071\nNAD27 11S\nNaN\n\n\n4\nIMP39-A\nNaN\n104.2\n1.2\nArdill et al., 2018\nZircon\nspot analyses\nPlutonic\nGrizzly Peak porphyritic tonalite\ngranodiorite of Grizzly Creek\nunassigned, Iron Mountain area\n278808\n4149668\nNAD27 11S\nNaN\n\n\n\n\n\n\n\n\n# Read in Shapefiles\n\ndef read_shapefiles_in_folder(folder_path):\n    'FUNCTION TO READ IN ALL SHAPEFILES FROM A FOLDERPATH'\n    shapefiles_dict = {}\n\n    # Check if the folder path exists\n    if not os.path.exists(folder_path):\n        raise FileNotFoundError(f\"The folder '{folder_path}' does not exist.\")\n\n    # Iterate through files in the folder\n    for filename in os.listdir(folder_path):\n        if filename.endswith(\".shp\"):\n            file_path = os.path.join(folder_path, filename)\n            # Extract file name without extension\n            file_name = os.path.splitext(filename)[0]\n            # Read shapefile into GeoDataFrame\n            gdf = gpd.read_file(file_path)\n            # Store GeoDataFrame in the dictionary\n            shapefiles_dict[file_name] = gdf\n            \n    return shapefiles_dict\n\nfolder_path = 'Data/raw/CentralSierraMapData_ForLily20231220'\n\ntry:\n    # Read shapefiles into a dictionary\n    shapefiles_data = read_shapefiles_in_folder(folder_path)\n\n    # Access GeoDataFrames by file name\n    for file_name, gdf in shapefiles_data.items():\n        print(f\"File Name: {file_name}\")\n        #print(gdf.head())  # Display the first few rows of the GeoDataFrame\n\nexcept FileNotFoundError as e:\n    print(e)\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")\n\nFile Name: CretaceousIntrusionsIndividualPolygons\nFile Name: CretaceousIntrusionsExtentPolygons\nFile Name: DetailedMapDataAreaBoundaryLine\nFile Name: IntrusiveSuitePolygons\n\n\nWe are interested in 2 of the shapefiles:\n\nDetailedMapDataAreaBoundaryLine: Provides boundary linestring of the area of interest.\nCretaceousIntrusionsIndividualPolygons: Provides polygon geometry with associated geologic time period in the area of interest.\n\n\n\nData Cleaning and Wrangling\nTo ensure the data is ready for analysis, we will handle missing values and add geospatial characteristics (POINT() shapes).\nAdditionally, we’ll also add some approximate ages to the periods in the shapefiles (late Cretaceous, early Cretaceous, and Jurassic Cretaceous), and then combine the shapefiles with like periods.\n\n# Clean csv\n \n# ------ Handle missing values ---------\n# When original name is NA, then originalName == AnalysisName\ndf_ages_raw['OriginalName'] = df_ages_raw['OriginalName'].fillna(df_ages_raw['AnalysisName']) \n# When easting & northing == \"NA*\" then convert to NA\ndf_ages_raw['Easting'] = pd.to_numeric(df_ages_raw['Easting'].replace('NA*', pd.NA), errors = 'coerce') \ndf_ages_raw['Northing'] = pd.to_numeric(df_ages_raw['Northing'].replace('NA*', pd.NA), errors = 'coerce')\n# Remove when location (easting or northing) is NA because location of age is a must have\ndf_ages = df_ages_raw[pd.notna(df_ages_raw['Easting']) & pd.notna(df_ages_raw['Northing'])].copy()\nprint(\"Size of cleaned csv data:\", len(df_ages))\n\n# ---------- Create POINT dataframe -----------\n# Make points a POINT() geometry\n# EPSG:26711\ndf_point = gpd.GeoDataFrame(df_ages, geometry=gpd.points_from_xy(df_ages.Easting, df_ages.Northing),  crs='epsg:26711')\n\n#### Get age statistics\nprint(\"\\nAge Statistics: \")\nprint(df_ages['Age'].describe())\n\n##### View distrubtion of ages\nplt.hist(df_ages['Age'], bins = 40)\nplt.xlabel(\"Ages\")\nplt.ylabel(\"Count\")\nplt.title(\"Distribution of Ages over Entire Area\")\nplt.figure(figsize=(.5, .5), dpi=80)\nplt.show()\n\nSize of cleaned csv data: 213\n\nAge Statistics: \ncount    213.000000\nmean      99.938685\nstd       10.301582\nmin       83.500000\n25%       91.450000\n50%       97.100000\n75%      106.300000\nmax      124.200000\nName: Age, dtype: float64\n\n\n\n\n\n\n\n\n\n&lt;Figure size 40x40 with 0 Axes&gt;\n\n\n\n# Clean shapefile\n\n# ------------- Add Numeric Approx Age ---------------\n#shapefiles_data[\"CretaceousIntrusionsIndividualPolygons\"].Age.unique()\n#array(['eK', 'KJ', 'lK', 'eK?', 'lK?'], dtype=object)\n# PERIODS:\n# J: 201.3-145.0 MYA\n# K: 145.0-66.0 MYA\n# Thus mapping eK to mean(145 and mean(145, 66)), lK to mean(mean(145, 66), 66) and KJ to 145\n# Note that the oldest point in df_ages is 124.2\nk_mean = (145+66)/2 ; eK_mean = (145+k_mean)/2; lk_mean = (k_mean+66)/2; kJ = 145;\n(shapefiles_data[\"CretaceousIntrusionsIndividualPolygons\"])[\"ageNum\"] = shapefiles_data[\"CretaceousIntrusionsIndividualPolygons\"].Age.apply(\n    lambda x: eK_mean if (x == 'eK' or x == 'eK?') else(lk_mean if (x == 'lK' or x == 'lK?') else kJ))\n    \n# Number of polygons in each shapefile:\nfor file, gdf in shapefiles_data.items():\n    print(f\"File: {file}   Number of shapes: {len(gdf)}\")\n\n##### View distrubtion of approximate ages\nplt.hist((shapefiles_data[\"CretaceousIntrusionsIndividualPolygons\"])[\"ageNum\"], bins = 40)\nplt.xlabel(\"Ages\")\nplt.ylabel(\"Count\")\nplt.title(\"Count of Approximate Ages of Polygons\")\nplt.figure(figsize=(.5, .5), dpi=80)\nplt.show()\n\nFile: CretaceousIntrusionsIndividualPolygons   Number of shapes: 1435\nFile: CretaceousIntrusionsExtentPolygons   Number of shapes: 189\nFile: DetailedMapDataAreaBoundaryLine   Number of shapes: 1\nFile: IntrusiveSuitePolygons   Number of shapes: 625\n\n\n\n\n\n\n\n\n\n&lt;Figure size 40x40 with 0 Axes&gt;\n\n\nThere are over 1400 shapes in our individual polygon file (with periods), but only 3 periods. For convenience we will combine polygons if they touch and have the same period.\n\n# ---------- Combined if polygon touching and same period ----------\nshapefiles_data['UnionPolygons'] = shapefiles_data[\"CretaceousIntrusionsIndividualPolygons\"].dissolve(by = 'Age')\n\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15,10))\nlegend_criteria = \"ageNum\"\nax[0].set_title(f'Individual Polygons')\nax[1].set_title(f'Union of Polygons')\n\nshapefiles_data[\"CretaceousIntrusionsIndividualPolygons\"].plot(figsize=(10, 10), alpha=0.5, edgecolor='k',column=legend_criteria, cmap='viridis', legend=False,ax=ax[0] )\nshapefiles_data['UnionPolygons'].plot(figsize=(10, 10), alpha=0.5, edgecolor='k',column=legend_criteria, cmap='viridis', legend=False,ax=ax[1] )\n\n\nplt.show()\n\n\n\n\n\n\n\n\nNote 1: The union creates 6 shapefiles because some of the periods are more uncertain and have a ?. For now, we are handling all periods as if they are all accurate, i.e. eK and eK? would not be combined, but would be labeled with the same approximate age.\nNote 2: The polynomials are only within the boundary of interest.\nNote 3: The union creates a shape called a “MULTIPOLINOMIAL” which we can ultimately handle the same as a normal POLYNOMIAL() geometry.\n\n\nExploratory Data Analysis\nNow that we have the cleaned data, we can start visualizing and exploring it. We already see that individual ages are mostly between 90-98 Million year ago (Ma), with average age of 99 Ma. Additionally, the polygons reference 3 periods.\nNote that while the above graph counts the number of polygons it doesn’t take into account the total area of the polygons. As we will see below the oldest polygons take up a very small amount of the area.\nLet’s first take a look at our map:\n\nfrom branca.colormap import linear\n# In order to color on the same scale we need to normalize ages between the two data sources\n# and create a color scale\nmin_age = min(min(df_point[\"Age\"]),min(shapefiles_data[\"UnionPolygons\"][\"ageNum\"]))\nmax_age = max(max(df_point[\"Age\"]),max(shapefiles_data[\"UnionPolygons\"][\"ageNum\"]))\ncolormap = linear.YlOrRd_09.scale(min_age, max_age)\n\n# IDs for each polygon in each shapefile\n(shapefiles_data[\"DetailedMapDataAreaBoundaryLine\"])[\"id\"] = shapefiles_data[\"DetailedMapDataAreaBoundaryLine\"].index.astype(str)\n# IDs for each polygon in each shapefile\n(shapefiles_data[\"UnionPolygons\"])[\"id\"] = shapefiles_data[\"UnionPolygons\"].index.astype(str)\n\n\n# Omitting plotting code here due to size\ninteractive_map\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\nUsing the interactive folium map, we can see that we have some polygons and data for about half of the boundary area.We have points outside of the boundary area, which is great as it gives us more information that will be helpful when making predictions.\nPreliminary trends indicate the ages of the samples get younger as we move eastward, This suggests that the general direction of magma movement was towards the east.\nLet’s add some additional features and see what else we can see.\n\n\nFeature Engineering (Part 1)\nWe will now perform the first set of feature engineering on our data. This involves converting Easting and Northing coordinates to longitude and latitude for ease of interpretation, and creating quartiles for these coordinates. Additionally, we will incorporate important spatial features such as elevation and the geological period belonging to polygon that each point falls into, with the periods one-hot encoded for scaling prior to model training.\nIf a point does not fall within a polygon, then its period will be None.\n\nIMPORTANT !!! The function get_elevation_batch() being used to get the elevation needs to be modified in order to run. Please go to the Running the Code section of the README for more information.\n\n\n# Feature Engineering - CSV File\n# ---------- Lat/Lng -----------------\nlat, long = utm.to_latlon(df_ages['Easting'], df_ages['Northing'], 11, 'S')\ndf_ages['lat'] = lat\ndf_ages['long'] = long\n\n####### GEOLOGIC FEATURES #############\n\n# ----------- Elevation ---------------\n# Sending batch is faster than individual (https://github.com/sgherbst/pyhigh#)\n#### NOTE: need to change get_url_for_zip() function in env/lib/python3.9/pyhigh/elevation.py to\n# def get_url_for_zip(zip_name):\n#    return f'https://firmware.ardupilot.org/SRTM/North_America/{zip_name}'\n# Described in issue here https://github.com/sgherbst/pyhigh/issues/1\ncoord_batch = list(zip(df_ages['lat'], df_ages['long']))\ndf_ages['elevation'] = get_elevation_batch(coord_batch)\n\n# ----------- Add Period of Corresponding Polygon --------------\n# NOTE: This will limit all predictions to within the border if used\n\n# Create POINT() by easting and northing\ngeometry = [Point(xy) for xy in zip(df_ages['Easting'], df_ages['Northing'])]\ndf_ages = gpd.GeoDataFrame(df_ages, geometry=geometry, crs=\"EPSG:26711\")\ndf_ages['period'] = \"None\"\n# Find if the point is within a polygon, and if so, assign it the corresponding period\nfor idx, point in df_ages.iterrows():\n    for period, polygon in shapefiles_data['UnionPolygons'].iterrows():\n        if point.geometry.intersects(polygon.geometry):\n            df_ages.at[idx, 'period'] = period\n            break  # Stop checking once the polygon is found\n            \n# Perform one hot encoding on period \ndf_ages['period_onehot'] = df_ages['period']\ndf_ages = pd.get_dummies(df_ages, columns=['period_onehot'])\n\nWe can look the number of points that fall into each period below (note that one point does into the KJ period, it’s just hard to see).\n\n# Look at the amount of points at each age in each period\nperiod = df_ages['period'].unique()\n\nfig, ax = plt.subplots(nrows=1, ncols=len(period), figsize=(15,5))\nplt.setp(ax, xlim=(80,130), ylim=(0, 16) )\nfor i, ax in enumerate(ax.flat):\n    df = df_ages[df_ages['period'] == period[i]]\n    \n    ax.hist(df['Age'], bins=10, alpha=0.7, stacked=False)\n    ax.set_xlabel('Age (Ma)')\n    ax.set_ylabel('Count')\n    ax.set_title(f'Period: {period[i]}')\n    ax.grid(True)\n\n\n\n\n\n\n\n\nAs we saw in the folium map, a lot of points are outside of the boundary region and do not fall into a polygon (i.e. period == \"None\"). But there are a decent amount of points in the eK and lK periods (only 1 in KJ).\nNext we can look at how the location specific features (Easting, Northing, and Elevation) relate to age.\n\n# Plot all features with age individually\nlist_to_plot = [\"Easting\", \"Northing\", \"elevation\"]\nfig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,5))\n\nfor i, ax in enumerate(ax.flat):\n    ax.scatter(df_ages[list_to_plot[i]], df_ages[\"Age\"], alpha=0.7, color='blue')\n    ax.set_xlabel(f'{list_to_plot[i]}')\n    ax.set_ylabel('Age (Ma)')\n\n\n\n\n\n\n\n\n\n# Plot all features together in 3D\nfig = px.scatter_3d(df_ages, x='Easting', y='Northing', z='elevation', color='Age',\n                    title = \"Age Distribution with Elevation (interact with me!)\")\nfig.update_layout(scene_zaxis_type=\"log\")\n\n                                                \n\n\nFrom these graphs, we note that easting and elevation are showing a stronger trend in relation to age than northing.\n\n\nTest/Train Split\nBefore training ML models, the data must be split into test and training sets. This is my first time working with GIS data and I was excited to learn about various test/train splitting methods when handling this sort of data. In addition to a traditional split, I tried out a Spatial KFold Splitting method, and a Cluster-Based Splitting method.\n\n# Split data into test and train \n\n# ----------- Traditional Split -----------------\n# Use if spatial autocorrelation is not significant concern\ntrain_trad, test_trad = train_test_split(df_ages, test_size=0.2, random_state=42)\n\n# ----------- Spatial K-Fold CV -----------------\n# Ensures spatially close points are either in training or testing (not both)\ncoordinates = df_ages[['lat', 'long']].values\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\n\nfor train_index, test_index in kf.split(coordinates):\n        train_kf, test_kf = df_ages.iloc[train_index], df_ages.iloc[test_index]\n\n# ----------- Cluster-Based Split ---------------\n# Cluster data points and then split each cluster into test/train\nkmeans = KMeans(n_clusters=10, random_state=42)\ndf_ages['cluster'] = kmeans.fit_predict(df_ages[['lat', 'long']])\n\ntrain_clust, test_clust = train_test_split(df_ages, test_size=0.2, stratify=df_ages['cluster'], random_state=42)\n\n################################################################################\n# Let's create a dictionary with the different test/train splits for convenience!\ndf_dict = {\n    'trad': {'train': train_trad,'test': test_trad},\n    'kf': {'train': train_kf,'test': test_kf},\n    'cluster': {'train': train_clust,'test': test_clust}\n}\n\nThe difference in how the methods split the data with respect to location:\n\n\n\n\n\n\n\n\n\nThe difference in how the methods split the data with respect to capturing age:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUltimately, I found that these advanced splitting methods did not significantly change the spatial representation or age distribution of my data compared to the traditional split. Additionally, I was concerned that these methods might not accurately represent my data for future predictions and could potentially lead to an overestimation of model accuracy by reducing the randomness in the splitting process. As a result, I will train the models with the traditionally split data.\nAs I learn more about ML with GIS data, I may revisit this. Please reach out if you have tips/advice!\n\n\nCross Validation\nTo ensure robust model evaluation for hyper-parameter tuning, we perform 5-fold cross-validation on my training set and store the results in a dictionary. I prefer using a dictionary for this purpose as it keeps everything organized and easily accessible!\n\n# Setting up k-fold cross-validation, and storing split in dictionary for easy access\nkf = KFold(n_splits=5) #5-folds\nfor key in df_dict.keys():\n    # Take training data set for test/train split method(traditional, cluster, kfold)\n    train = df_dict[key]['train']\n    \n    # Split data into the 5 folds from TRAIN\n    # Store in a dictionary (cv) with all test and train splits\n    cv = {}\n    for i, (train_index, test_index) in enumerate(kf.split(train)):\n        cv[f'fold_{i}'] = {\n        'train': train.iloc[train_index],\n        'test': train.iloc[test_index],\n        'train_idx': train_index,\n        'test_idx': test_index\n    }\n    # Add the cv dictionary to the original df_dict dictionary with all of the test/train splits\n    df_dict[key]['cv'] = cv\n\n\nSecond Round of Feature Engineering\nWithin the cross-validation sets, I perform a second round of feature engineering to prevent data leakage and preserve the integrity of the model’s predictions. It’s crucial to avoid allowing the models to see the testing data, even within cross-validation folds.\nWhy not let GridSearchCV() split the data into k-folds?\nWhile it might seem convenient to let GridSearchCV handle cross-validation, there’s an important reason for this approach. We already have some good features, but it’s vital to provide the data with additional context about its surroundings. Specifically, for a given point o_0, I calculate the age, distance, and angle of the next closest points: o_1, o_2, and o_3. This is done in two dimensions (combining Easting and Northing) and individually for Easting, Northing, and Elevation in one dimension.\nPreventing Leakage and Overfitting\nA major concern in this process is data leakage, which occurs when the training data gets insights from the testing data, potentially leading to overfitting. To prevent this, we add these features only after all splitting has been completed:\n\nTraining Data: The training data will have age/distance/bearing labels based on the training data itself.\nTest Data: Both the hold-out and cross-validation test sets will have age/distance/bearing labels based on the training data only.\n\nUsing GridSearchCV() for Hyper-Parameter Tuning\nFor hyper-parameter tuning of most models, I use GridSearchCV(). To integrate the second round of feature engineering, I define a custom cross-validation (CV) class that uses the predefined CV indices along with the training set. This class adds the new features to the training and testing folds separately before training the models.\n\n# Post Split Feature Engineering - Only using training data as reference\n\n# &lt;--------- Closest n Ages + Direction + Bearing -------------&gt;\n# We will calculate age of the closest 3 points in for each direction individually (northing/easting/elevation),\n# and top-down in 2 dimensions (easting+northing): Adding age, direction and bearing for each\n\n# FUNCTIONS CALCULATING METRICS ARE OMITTED HERE #\n\nstart = time.time()\n\n# For each method of splitting, for each cross-validation training set calculate the above\nfor key in df_dict.keys():\n    ### Full Testing ###\n    df = df_dict[key]['test']\n    ref = df_dict[key]['train']\n    df = df.apply(lambda row: pd.concat([row, get_closest_points_metrics(\n      selected_point=row, reference_df= ref,  training_point=False)]), axis=1)\n    df_dict[key]['test'] = df\n    \n    for fold in df_dict[key]['cv']:\n        ### K-Fold Training ###\n        # Assign the data we want to make calculations on \n        df = df_dict[key]['cv'][fold]['train']\n        # Call function on each row\n        # NOTE: Because we are labeling training data with training data we need to specify this to the function\n        # so that it can remove this point from the reference dataset\n        # (this is needed because when we label the test data we use training data as the reference and won't be removing the point\n        df = df.apply(lambda row: pd.concat([row, get_closest_points_metrics(\n          selected_point=row, reference_df= df, training_point=True)]), axis=1)\n        df_dict[key]['cv'][fold]['train'] = df\n        \n        ### K-Fold Testing ###\n        # Assign the data we want to make calculations on \n        df = df_dict[key]['cv'][fold]['test']\n        # Ref is training set (same as before)\n        # Training_point = False this time\n        df = df.apply(lambda row: pd.concat([row, get_closest_points_metrics(\n          selected_point=row, reference_df= ref, training_point=False)]), axis=1)\n        df_dict[key]['cv'][fold]['test'] = df\n\n\nend = time.time()\nprint('Time taken to calculate metrics: ' + str(end - start) + \" seconds\")\n\nTime taken to calculate metrics: 20.46400213241577 seconds\n\n\n\nclass CustomCVSplitter(BaseCrossValidator):\n    \n    def __init__(self, cv_indices, feature_list):\n        self.cv_indices = cv_indices\n        self.feature_list = feature_list\n        \n    def split(self, X, y=None, groups=None):\n        # Define the folds from the indices given\n        for fold, (train_idx, test_idx) in enumerate(self.cv_indices):\n            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n\n            # Apply feature engineering \n            X_train = X_train.apply(lambda row: pd.concat([row, get_closest_points_metrics(\n              selected_point=row, reference_df= X_train,  training_point=True)]), axis=1)\n            X_test = X_test.apply(lambda row: pd.concat([row, get_closest_points_metrics(\n              selected_point=row, reference_df= X_train, training_point=False)]), axis=1)\n        \n            # Remove Age from all X (age is target)\n            X_train = X_train[self.feature_list]\n            X_test = X_test[self.feature_list]\n\n            yield train_idx, test_idx\n            \n        \n        \n    def get_n_splits(self, X=None, y=None, groups=None):\n        return len(self.cv_indices)\n    \n    def __len__(self):\n        return self.get_n_splits()"
  },
  {
    "objectID": "portfolio/projects/sierraNevadaAge/writeup.html#training-models",
    "href": "portfolio/projects/sierraNevadaAge/writeup.html#training-models",
    "title": "Geologic Magmatic Migration Exploration Through Age Prediction",
    "section": "Training Models",
    "text": "Training Models\nIn this section, I will walk through the training process for two out of the five models I’ve trained on this data: a K-Nearest Neighbor (KNN) model and a Gradient Boosting Machine (GBM) model. For the KNN model, we will manually tune the parameters and select the best one. For the GBM model, we will demonstrate how to use the custom cross-validation and pipeline functionality with GridSearchCV().\nThe full list of models trained in this project includes:\n\nDecision Tree\nRandom Forest\nGradient Boosting Machine (GBM)\nK-Nearest Neighbor (KNN)\nGaussian Process Regressor\n\nThe full code, including training for all models, is available at the link provided at the top.\nLet’s get started!\nBefore diving into the specific models, let’s define and initialize a few key components to ensure the training process runs smoothly.\n\n# Select the traditionally split data\ndf_test_train = df_dict['trad']\n\n# Set list of features and target\ntarget = list([\"Age\"])\nlist_features = list(['Easting', 'Northing', 'elevation', 'period_onehot_KJ', 'period_onehot_None', 'period_onehot_eK', 'period_onehot_lK', \n                      'age_1d_northing_1', 'distance_1d_northing_1', 'bearing_1d_northing_1',\n                      'age_1d_northing_2', 'distance_1d_northing_2', 'bearing_1d_northing_2',\n                       'age_1d_northing_3', 'distance_1d_northing_3', 'bearing_1d_northing_3',\n                       'age_1d_easting_1', 'distance_1d_easting_1', 'bearing_1d_easting_1',\n                       'age_1d_easting_2', 'distance_1d_easting_2', 'bearing_1d_easting_2',\n                       'age_1d_easting_3', 'distance_1d_easting_3', 'bearing_1d_easting_3',\n                       'age_1d_elevation_1', 'distance_1d_elevation_1',\n                       'bearing_1d_elevation_1', 'age_1d_elevation_2',\n                       'distance_1d_elevation_2', 'bearing_1d_elevation_2',\n                       'age_1d_elevation_3', 'distance_1d_elevation_3',\n                       'bearing_1d_elevation_3', 'age_2d_1', 'distance_2d_1', 'bearing_2d_1',\n                       'age_2d_2', 'distance_2d_2', 'bearing_2d_2', 'age_2d_3',\n                       'distance_2d_3', 'bearing_2d_3'])\n# Why do we include age? because we need it in order to add features within our custom_cv - we will remove age though so that it is not in our training set\nlist_features_pre_split = list(['Age','geometry','Easting', 'Northing', 'elevation', 'period_onehot_KJ', 'period_onehot_None', 'period_onehot_eK', 'period_onehot_lK'])\n\n# Set iterable yielding (train, test) splits as arrays of indices for GridSearchCV()\ndf_test_train['cv'].keys()\ncv_idx_split = list([])\n\nfor key in df_test_train['cv'].keys():\n    train_list = df_test_train['cv'][key]['train_idx'].tolist()\n    test_list = df_test_train['cv'][key]['test_idx'].tolist()\n    cv_idx_split.append((train_list, test_list))\n    \n    \n# Initialize a custom_cv\ncustom_cv = CustomCVSplitter(cv_idx_split, list_features)\n    \n# Initialize model metrics\ndf_test_train['model_metrics'] = {}\n\n\nK-Nearest Neighbors\nThe K-Nearest Neighbors (KNN) algorithm is a versatile, non-parametric supervised learning method that makes predictions based on the k nearest points to a given data point. The challenge lies in determining the optimal number of nearest points (k) to use. To start, we will try k values ranging from 1 to 20 and evaluate the average RMSE (Root Mean Squared Error) across the cross-validation folds for each k.\n\n# ----------- Hyper-Parameter Tuning -------------\nmax_k = 20\n\n# On each fold:\n#   =&gt; On each k (num neighbors):\n#       =&gt; train model \n#       =&gt; predict age in each test set with model (to make easier, make new dict {k: []} | for all k}\nfold_dict = {k: {\"train\": [], \"test\": []} for k in range(1, max_k+1)}\nfor k in range (1, max_k+1):\n    # Set k\n    knn = KNeighborsRegressor(n_neighbors=k)\n    \n    # Train for each fold\n    for fold in df_test_train['cv'].keys():\n        # Set test and train x and y \n        X_train = df_test_train['cv'][fold]['train'][list_features]\n        y_train = df_test_train['cv'][fold]['train'][target]\n        X_test = df_test_train['cv'][fold]['test'][list_features]\n        y_test = df_test_train['cv'][fold]['test'][target]\n        \n        # Scale features\n        scaler = StandardScaler()\n        X_train = scaler.fit_transform(X_train)\n        X_test = scaler.transform(X_test)\n        \n        # Train knn model \n        knn.fit(X_train, y_train) \n        \n        # Predict test\n        pred_test = knn.predict(X_test)\n        pred_train = knn.predict(X_train)\n        \n        # Calculate RMSE\n        rmse_test = np.sqrt(mean_squared_error(y_test, pred_test))\n        rmse_train = np.sqrt(mean_squared_error(y_train, pred_train))\n        fold_dict[k]['test'].append(rmse_test)\n        fold_dict[k]['train'].append(rmse_train)\n\nLet’s plot the RMSE values for different k neighbors and choose the best k based on the “elbow” of the test RMSE curve. From the graph below, it appears that the optimal k is 4.\n\n# ---------------- Select Model ------------------\ntest = list([])\ntrain = list([])\nfor k in fold_dict.keys():\n   train.append(np.mean(fold_dict[k]['train'])) \n   test.append(np.mean(fold_dict[k]['test']))\n   \nplt.plot(train, c='b', label='train')\nplt.plot(test, c='r', label='test')\nplt.legend()\nplt.title(\"KNN: Average RMSE over 5-folds\")\nplt.xlabel(\"k Neighbors\")\nplt.ylabel(\"RMSE\")\nplt.show()\n# We want to select k where the \"elbow\" in the below graph appears.\n# It looks like this is when k = 4\nk_bestmodel = 4\n\n\n\n\n\n\n\n\nWith the optimal k determined, we can now train the KNN model on the entire training set using k=4.\nIt’s important to add the closest point metric features to the training set at this stage. The reason for this is that, unlike the other models which will use the training set in GridSearchCV for parameter tuning, we are manually tuning the KNN model. If we had added these features earlier, it would have introduced information about the test set into the training set, leading to data leakage when we use GridSearchCV.\n\n# ------- Train Model on all Training Data -------\n# Now that we chose our parameter as 5, we will train and test on the full training and test set\nknn = KNeighborsRegressor(n_neighbors=k_bestmodel)\n# Set test and train x and y \nX_train = df_test_train['train'].apply(lambda row: pd.concat([row, get_closest_points_metrics(selected_point=row, reference_df= df_test_train['train'], num_closest=3, training_point=True)]), axis=1)\nX_train = X_train[list_features]\ny_train = df_test_train['train'][target]\nX_test = df_test_train['test'][list_features]\ny_test = df_test_train['test'][target]\n        \n# Scale features\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n        \n# Train knn model \nknn.fit(X_train, y_train) \n        \n# Predict test\npred_test = knn.predict(X_test)\npred_train = knn.predict(X_train)\n        \n# Calculate RMSE\nrmse_test = np.sqrt(mean_squared_error(y_test, pred_test))\n# Calculate r2\nr2_test = r2_score(y_test, pred_test)\nprint(\"R2: \"+ str(r2_test))\n\n#### Add metrics to dictionary\ndf_test_train['model_metrics']['knn'] = {'model':knn, 'name': \"knn\",'rmse': rmse_test, 'r2': r2_test,'predicted_test': pred_test}\n\n\n#### Plot \nplt.scatter(y_test, pred_test, color='b')\nplt.plot(y_test, y_test, color = 'black')\nplt.title(\"KNN: Test Age vs. Predicted Test Age\")\nplt.xlabel(\"Age (Ma)\")\nplt.ylabel(\"Predicted Age (Ma)\")    \n\nplt.show()\n\nR2: 0.7317981808153224\n\n\n\n\n\n\n\n\n\n\n\nGradient Boosting Machine\nFor the GBM model, we will use GridSearchCV in combination with the custom cross-validation class defined earlier and the pipeline defined below. In our parameter grid, each parameter name must be prefixed with model__ to ensure that GridSearchCV correctly applies the parameters to the appropriate part of the pipeline. This setup allows us to systematically search for the best parameters while leveraging the benefits of cross-validation.\n\n# Train model on all folds (indices for our cv already specified in grid_search)\nX_train = df_test_train['train'][list_features_pre_split]\ny_train = df_test_train['train'][target]\nX_test = df_test_train['test'][list_features]\ny_test = df_test_train['test'][target]\n\n\n# ----------- Hyper-Parameter Tuning -------------\nparam_grid = {\n    'model__n_estimators': [50, 100, 200],\n    'model__max_depth': [3, 5, 7],\n    'model__min_samples_split':[2,4,6,8,10,20,40,60,100], \n    'model__min_samples_leaf':[1,3,5,7,9]\n}\n\npipeline = Pipeline([\n    ('remove_columns', FunctionTransformer(problem_columns)),\n    ('model', GradientBoostingRegressor())\n])\n\nmodel = 'gradient_boosting_regressor'\n\ngrid_search = GridSearchCV(pipeline, param_grid, cv=custom_cv, scoring='neg_mean_squared_error', n_jobs=-1,\n                           error_score='raise').fit(X_train, y_train.values.ravel())\n\ngrid_search\n\n/Users/lilynorthcutt/Documents/Projects/portfolio_git/env/lib/python3.12/site-packages/numpy/ma/core.py:2846: RuntimeWarning:\n\ninvalid value encountered in cast\n\n\n\nGridSearchCV(cv=CustomCVSplitter(cv_indices=[([34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 10...50, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169])],\n         fe...\n             estimator=Pipeline(steps=[('remove_columns',\n                                        FunctionTransformer(func=&lt;function problem_columns at 0x14872b9c0&gt;)),\n                                       ('model', GradientBoostingRegressor())]),\n             n_jobs=-1,\n             param_grid={'model__max_depth': [3, 5, 7],\n                         'model__min_samples_leaf': [1, 3, 5, 7, 9],\n                         'model__min_samples_split': [2, 4, 6, 8, 10, 20, 40,\n                                                      60, 100],\n                         'model__n_estimators': [50, 100, 200]},\n             scoring='neg_mean_squared_error')In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  GridSearchCV?Documentation for GridSearchCViFittedGridSearchCV(cv=CustomCVSplitter(cv_indices=[([34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 10...50, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169])],\n         fe...\n             estimator=Pipeline(steps=[('remove_columns',\n                                        FunctionTransformer(func=&lt;function problem_columns at 0x14872b9c0&gt;)),\n                                       ('model', GradientBoostingRegressor())]),\n             n_jobs=-1,\n             param_grid={'model__max_depth': [3, 5, 7],\n                         'model__min_samples_leaf': [1, 3, 5, 7, 9],\n                         'model__min_samples_split': [2, 4, 6, 8, 10, 20, 40,\n                                                      60, 100],\n                         'model__n_estimators': [50, 100, 200]},\n             scoring='neg_mean_squared_error') best_estimator_: PipelinePipeline(steps=[('remove_columns',\n                 FunctionTransformer(func=&lt;function problem_columns at 0x14872b9c0&gt;)),\n                ('model',\n                 GradientBoostingRegressor(max_depth=5, min_samples_leaf=5,\n                                           min_samples_split=6,\n                                           n_estimators=50))])  FunctionTransformer?Documentation for FunctionTransformerFunctionTransformer(func=&lt;function problem_columns at 0x14872b9c0&gt;)  GradientBoostingRegressor?Documentation for GradientBoostingRegressorGradientBoostingRegressor(max_depth=5, min_samples_leaf=5, min_samples_split=6,\n                          n_estimators=50) \n\n\nNow we can select the best parameters below:\n\n# ---------------- Select Model ------------------\nbest_params = grid_search.best_params_\nprint(best_params)\n\n{'model__max_depth': 5, 'model__min_samples_leaf': 5, 'model__min_samples_split': 6, 'model__n_estimators': 50}\n\n\nWith the best parameters identified, we can retrain the GBM model on the full training set using these parameters. Finally, we will make predictions on the test set and evaluate the model’s performance.\n\n# ------- Train Model on all Training Data -------\n# Add features to full training set:\nX_train = X_train.apply(lambda row: pd.concat([row, get_closest_points_metrics(selected_point=row, reference_df= X_train, \n                                                                             num_closest=3, training_point=True)]), axis=1)\nX_train = X_train[list_features]\n\n# Fit rf with the full training dataset\nbest_pipeline = Pipeline([\n    ('remove_columns', FunctionTransformer(problem_columns)),\n    ('model', GradientBoostingRegressor(**{k.replace('model__', ''): v for k, v in best_params.items()}))\n])\nbest_pipeline.fit(X_train, y_train.values.ravel())\n\n# Predict test\npred_test = best_pipeline[1].predict(X_test)\n\n# Calculate RMSE\nrmse_test = np.sqrt(mean_squared_error(y_test, pred_test))\n# Calculate r2\nr2_test = r2_score(y_test, pred_test)\nprint(\"R2: \"+ str(r2_test))\n\n\n\n#### Add metrics to dictionary\ndf_test_train['model_metrics']['gbm'] = {'model':best_pipeline[1], 'name': model,'rmse': rmse_test, 'r2': r2_test,'predicted_test': pred_test}\n\n\n#### Plot \nplt.scatter(y_test, pred_test, color='b')\nplt.plot(y_test, y_test, color = 'black')\nplt.title(\"GBM: Test Age vs. Predicted Test Age\")\nplt.xlabel(\"Age (Ma)\")\nplt.ylabel(\"Predicted Age (Ma)\")    \n\nplt.show()\n\nR2: 0.7430508763208055"
  },
  {
    "objectID": "portfolio/projects/sierraNevadaAge/writeup.html#evaluate",
    "href": "portfolio/projects/sierraNevadaAge/writeup.html#evaluate",
    "title": "Geologic Magmatic Migration Exploration Through Age Prediction",
    "section": "Evaluate",
    "text": "Evaluate\nAfter training all our models, we can assess their performance using metrics such as the RMSE (Root Mean Squared Error) and the R2 score. The following table summarizes these metrics for each model:\n\n\n+----------------------------+------+------+\n|           Model            | RMSE |  R2  |\n+----------------------------+------+------+\n|       Decision Tree        | 6.78 | 0.57 |\n|       Random Forest        | 5.82 | 0.68 |\n|            GBM             | 5.26 | 0.74 |\n|            KNN             | 5.38 | 0.73 |\n| Gaussian Process Regressor | 4.55 | 0.81 |\n+----------------------------+------+------+\n\n\nFrom the table, we can see that the Gaussian Process Regressor is the best-performing model, with an R2 score of 0.81. This indicates that the Gaussian Process Regressor explains a significant portion of the variance in the data.\nTo gain further insights into the models, we can explore feature importance. For models like Decision Trees, Random Forests, and Gradient Boosting Machines (GBM), we can use built-in methods to obtain feature importance scores. Otherwise, we use permutation importance to assess the impact of each feature on model performance. I won’t be addressing this here as I only trained two of the models in this writeup.\nFor practical applications, including integration into the Shiny app, we will retrain the selected model (Gaussian Process Regressor with the best parameters) using all available data. This final model will be used for predicting and forecasting unknown data points."
  },
  {
    "objectID": "portfolio/projects/sierraNevadaAge/writeup.html#conclusion",
    "href": "portfolio/projects/sierraNevadaAge/writeup.html#conclusion",
    "title": "Geologic Magmatic Migration Exploration Through Age Prediction",
    "section": "Conclusion",
    "text": "Conclusion\nThis project successfully developed and applied new (ML) methods to address critical gaps in geologic maps by predicting undated rock ages within the Sierra Nevadas. By leveraging advanced algorithms, including Decision Trees, Random Forests, Gradient Boosting Machines, K-Nearest Neighbors, and Gaussian Process Regressors, we have provided valuable insights into magmatic migration and rock formation processes. The Gaussian Process Regressor emerged as the top performer, offering a robust model with an R2 score of 0.81.\nThis approach allows us to present a less biased view of magmatic migration, enhancing our understanding of the geological history in the Sierra Nevadas.\nAdditionally, the interactive visualizations in Shiny enable researchers and interested individuals to explore the data and predictions (predictions coming soon). These visualizations offer an intuitive and engaging way to examine geologic ages, model predictions, and spatial relationships, making the data more accessible and informative."
  },
  {
    "objectID": "portfolio/projects/sierraNevadaAge/writeup.html#future-work",
    "href": "portfolio/projects/sierraNevadaAge/writeup.html#future-work",
    "title": "Geologic Magmatic Migration Exploration Through Age Prediction",
    "section": "Future Work",
    "text": "Future Work\nThis was my first project working with GIS data, and I have lots of ideas I would like to explore. Here are a few ideas:\nEnhanced ML Methods:\n\nInvestigate more sophisticated ML models, including deep learning techniques and geospatial neural networks to improve accuracy and robustness\nFurther optimization of model parameters through methods such as Bayesian optimization\n\nBroadening Application Results:\n\nFinding other use case areas to apply the methodology explored here, and compare results to see if this methodology can be applied universally or only at this location\n\nImproving Shiny Visualizations:\n\nAdd Models: Add grid of boundary area predicted by models to show ages predicted uniformly over the area\nAge Histogram: Add histogram of ages corresponding to the ages in the map (lines up with the Age sliderbar)\nCustom Line Predictions: Add functionality for users to select a model, and specify a line within the boundary. The app will then generate predictions of ages along the line and output a 2D graph of line vs. age.\n\nThank you for stopping by and reading through my work!\nPlease feel free to reach out with any comments or suggestions.\n."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "Hi, I’m Lily.\nI’m a data scientist who loves turning abstract problems into clear, actionable solutions.\nI help scientists, researchers, and leaders tackle their toughest challenges by guiding them through the entire data science process — from gathering and cleaning data to applying machine learning, artificial intelligence, and statistical analysis.\nMy goal is to empower users to make informed, data-driven decisions and gain deeper insights through compelling visualizations and build interactive tools."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Lily Northcutt",
    "section": "",
    "text": "Hi, my name is Lily.\nI’m a Data Scientist who enjoys applying machine learning (ML) to challenging problems across various fields, and building visualization tools to communicate findings.\nFeel free to explore my projects to see my work in action. Thanks for stopping by!"
  },
  {
    "objectID": "portfolio/projects/heartdisease.html",
    "href": "portfolio/projects/heartdisease.html",
    "title": "Heart Disease Indicators by Sex",
    "section": "",
    "text": "Heart disease is a leading cause of mortality worldwide, yet significant gender disparities exist in its study and treatment. Historically, research has predominantly focused on male patients, resulting in diagnostic and treatment protocols that do not fully address the unique ways in which heart disease manifests in women. This oversight has led to a critical gap in our understanding and care of heart disease in women.\nThe original data can be found here. I have already saved it as a csv file and will be accessing this file. Mutliple researchers have explored this data and gotten good predictions on the data!\nThe goal of this project is to explore how sex plays a role in heart disease indicators. By doing so, we aim to provide medical professionals with deeper insights into the early indicators of heart disease and ensure that sex-specific factors are considered for improved diagnosis and treatment.\nTo get started lets read in the data and take a look at the first 5 rows.\n\npackages &lt;- c(\"tidyr\", \"readxl\", \"dplyr\", \"magrittr\", \"purrr\", \n              \"ggplot2\", \"stringr\", \"snakecase\", \"knitr\", \"caret\",\n              \"rpart\", \"rpart.plot\") \ninvisible(lapply(packages, require, character.only = TRUE ))\n\n\ndf_raw &lt;- read.csv(\"data/heart_disease.csv\")\nkable(df_raw[1:5,], caption = \"Raw Data\")\n\n\nRaw Data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nage\nsex\ncp\ntrestbps\nchol\nfbs\nrestecg\nthalach\nexang\noldpeak\nslope\nca\nthal\nnum\n\n\n\n\n63\n1\n1\n145\n233\n1\n2\n150\n0\n2.3\n3\n0\n6\n0\n\n\n67\n1\n4\n160\n286\n0\n2\n108\n1\n1.5\n2\n3\n3\n2\n\n\n67\n1\n4\n120\n229\n0\n2\n129\n1\n2.6\n2\n2\n7\n1\n\n\n37\n1\n3\n130\n250\n0\n0\n187\n0\n3.5\n3\n0\n3\n0\n\n\n41\n0\n2\n130\n204\n0\n2\n172\n0\n1.4\n1\n0\n3\n0\n\n\n\n\nna_cols &lt;- names(which(colSums(is.na(df_raw)) &gt; 0))\nprint(na_cols)\n\n[1] \"ca\"   \"thal\"\n\n\nThe data consists of 14 columns, including num which is our heart disease number. Two of these columns have NA values: ca and thal. Lets clean up the data and start exploring what we have."
  },
  {
    "objectID": "portfolio/projects/heartdisease.html#introduction",
    "href": "portfolio/projects/heartdisease.html#introduction",
    "title": "Heart Disease Indicators by Sex",
    "section": "",
    "text": "Heart disease is a leading cause of mortality worldwide, yet significant gender disparities exist in its study and treatment. Historically, research has predominantly focused on male patients, resulting in diagnostic and treatment protocols that do not fully address the unique ways in which heart disease manifests in women. This oversight has led to a critical gap in our understanding and care of heart disease in women.\nThe original data can be found here. I have already saved it as a csv file and will be accessing this file. Mutliple researchers have explored this data and gotten good predictions on the data!\nThe goal of this project is to explore how sex plays a role in heart disease indicators. By doing so, we aim to provide medical professionals with deeper insights into the early indicators of heart disease and ensure that sex-specific factors are considered for improved diagnosis and treatment.\nTo get started lets read in the data and take a look at the first 5 rows.\n\npackages &lt;- c(\"tidyr\", \"readxl\", \"dplyr\", \"magrittr\", \"purrr\", \n              \"ggplot2\", \"stringr\", \"snakecase\", \"knitr\", \"caret\",\n              \"rpart\", \"rpart.plot\") \ninvisible(lapply(packages, require, character.only = TRUE ))\n\n\ndf_raw &lt;- read.csv(\"data/heart_disease.csv\")\nkable(df_raw[1:5,], caption = \"Raw Data\")\n\n\nRaw Data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nage\nsex\ncp\ntrestbps\nchol\nfbs\nrestecg\nthalach\nexang\noldpeak\nslope\nca\nthal\nnum\n\n\n\n\n63\n1\n1\n145\n233\n1\n2\n150\n0\n2.3\n3\n0\n6\n0\n\n\n67\n1\n4\n160\n286\n0\n2\n108\n1\n1.5\n2\n3\n3\n2\n\n\n67\n1\n4\n120\n229\n0\n2\n129\n1\n2.6\n2\n2\n7\n1\n\n\n37\n1\n3\n130\n250\n0\n0\n187\n0\n3.5\n3\n0\n3\n0\n\n\n41\n0\n2\n130\n204\n0\n2\n172\n0\n1.4\n1\n0\n3\n0\n\n\n\n\nna_cols &lt;- names(which(colSums(is.na(df_raw)) &gt; 0))\nprint(na_cols)\n\n[1] \"ca\"   \"thal\"\n\n\nThe data consists of 14 columns, including num which is our heart disease number. Two of these columns have NA values: ca and thal. Lets clean up the data and start exploring what we have."
  },
  {
    "objectID": "portfolio/projects/heartdisease.html#data-cleaning-and-initial-observations",
    "href": "portfolio/projects/heartdisease.html#data-cleaning-and-initial-observations",
    "title": "Heart Disease Indicators by Sex",
    "section": "Data Cleaning and Initial Observations",
    "text": "Data Cleaning and Initial Observations\nFirst, let’s label the data in an easier way to understand for num (heart disease), and sex.\n\n# Add yes/no heart disease column\n# Label sex as male/female for convenience\ndf &lt;- df_raw %&gt;% \n  mutate( heart_disease = case_when(\n    num == 0 ~\"None\", T ~\"Present\"),\n    sex = case_when(sex==1 ~\"male\", T ~\"female\"))\n\n# View data with NA values\nkable(df %&gt;% filter(if_any(everything(), is.na)))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nage\nsex\ncp\ntrestbps\nchol\nfbs\nrestecg\nthalach\nexang\noldpeak\nslope\nca\nthal\nnum\nheart_disease\n\n\n\n\n53\nfemale\n3\n128\n216\n0\n2\n115\n0\n0.0\n1\n0\nNA\n0\nNone\n\n\n52\nmale\n3\n138\n223\n0\n0\n169\n0\n0.0\n1\nNA\n3\n0\nNone\n\n\n43\nmale\n4\n132\n247\n1\n2\n143\n1\n0.1\n2\nNA\n7\n1\nPresent\n\n\n52\nmale\n4\n128\n204\n1\n0\n156\n1\n1.0\n2\n0\nNA\n2\nPresent\n\n\n58\nmale\n2\n125\n220\n0\n0\n144\n0\n0.4\n2\nNA\n7\n0\nNone\n\n\n38\nmale\n3\n138\n175\n0\n0\n173\n0\n0.0\n1\nNA\n3\n0\nNone\n\n\n\n\n# Remove NAs\ndf %&lt;&gt;% drop_na()\n\n# Plot heart disease vs. no disease \nggplot(df, aes(x = heart_disease, fill = sex))+\n  geom_bar(position = position_dodge())+\n  ggtitle(\"Count of Detected Heart Disease for Women and Men\")+xlab(\"Heart Disease\")\n\n\n\n\n\n\n\n# Sex split in the data\nprint(paste0(\"Number of women: \", df %&gt;% filter(sex == 'female') %&gt;% nrow(),\"   \",\n             \"Number of men: \", df %&gt;% filter(sex == 'male') %&gt;% nrow()))\n\n[1] \"Number of women: 96   Number of men: 201\"\n\n# Heart Disease numbers by sex\nmen &lt;- paste0(\"Men with HD:  \", df %&gt;% filter(sex == 'male', heart_disease == 'Present') %&gt;% nrow())\nwomen &lt;- paste0(\"Women with HD:  \", df %&gt;% filter(sex == 'female', heart_disease == 'Present') %&gt;% nrow())\nstats_to_print &lt;- paste(men, women, sep = \"\\n\")\n\ncat(stats_to_print[1])\n\nMen with HD:  112\nWomen with HD:  25\n\n\n\nnormalize &lt;- function(x) {\n  return ((x - min(x)) / (max(x) - min(x)))\n}\n\n# Plot avg across all features for men and women\ndf %&gt;% select(-num) %&gt;% mutate_at(vars(-sex, -heart_disease), normalize)%&gt;% \n  group_by(sex, heart_disease) %&gt;%  summarise_all(mean) %&gt;%  ungroup() %&gt;% \n  pivot_longer(cols= !c(\"sex\", \"heart_disease\"), names_to = 'feature', values_to = 'mean') %&gt;% \n  ggplot()+\n  geom_point(aes(x = feature, y = mean, color = sex))+coord_flip()+facet_wrap(.~heart_disease)+ xlab(\"\")+ylab(\"Normalized Mean\")+\n  ggtitle(\"Feature Means Split By Heart Disease Present vs. None\")\n\n\n\n\n\n\n\n\nDuring the data cleaning process, six data points were removed due to missing information. While imputation methods could be considered to address this issue, for the purpose of this project, I have chosen to omit this step. The primary goal here is to understand the impact of sex on predicting heart disease, rather than achieving the highest possible prediction accuracy.\nAn initial review of the dataset reveals a significant gender imbalance, with more men represented in the study than women. This is true for both individuals diagnosed with heart disease and those without. The graph of feature means illustrates differences between feature expression for those with and without heart disease. Additionally, certain features, such as thal, oldpeak, and exang, display distinct variations between men and women. This suggests that the same approach to finding heart disease indicators may not be equally effective for both men and women."
  },
  {
    "objectID": "portfolio/projects/heartdisease.html#decision-tree-models",
    "href": "portfolio/projects/heartdisease.html#decision-tree-models",
    "title": "Heart Disease Indicators by Sex",
    "section": "Decision Tree Models",
    "text": "Decision Tree Models\nBringing it back to our original goal, to explore how sex plays a role in heart disease indicators, I am going to look at a series of decision trees.\n\nWhy Decision Trees?\nDecision trees may not always be the best models that give the highest predictive accuracy, however I think are a great model to use to help us understand our problem at hand.\nDecision trees are easy to understand and interpret, making the logic behind the predictions clear. This transparency is particularly valuable in the medical field, where it is crucial to explain why certain features are indicative of heart disease. Unlike more complex models such as neural networks, decision trees do not require dimensionality reduction, and they can directly use the original features of the dataset. This simplicity helps maintain the medical terminology and context, making the results more accessible and actionable for healthcare professionals.\n\n\nBuilding the Models\nTo understand how women and men are represented within the model, lets build three decision trees:\n\nFull Tree: This tree will be built using the training set from all the data.\nMale Tree: This tree will be built using the training set from the data filtered to sex == 'male'.\nFemale Tree: This tree will be built using the training set from the data filtered to sex == 'female'\n\nAll trees will use a 70/30 training/test split, and use the gini index within the tree.\n\nI will not be performing any hyper-parameter tuning in this project. Please take a look at a one of my more in-depth project, such as this one, if you are interested in this.\n\n\n# Set seed for reproducebility\nset.seed(1)\n\n# Remove num \ndf %&lt;&gt;% select(-num) \n\n# Split the data into test/train sets\n#### Men\ndf_m &lt;- df %&gt;% filter(sex == 'male')\nidx_m &lt;- createDataPartition(df_m$sex,p=0.7,list=FALSE)\ntrain_m &lt;- df_m[idx_m, ]\ntest_m &lt;- df_m[-idx_m, ]\n\n#### Women\ndf_w &lt;- df %&gt;% filter(sex == 'female')\nidx_w &lt;- createDataPartition(df_w$sex,p=0.7,list=FALSE)\ntrain_w &lt;- df_w[idx_w, ]\ntest_w &lt;- df_w[-idx_w, ]\n\ntrain &lt;- rbind(train_m, train_w)\ntest &lt;- rbind(test_m, test_w)\n\n# Percent of heart disease in train and test\nmen_percent &lt;- paste(\"Men:\",\n  paste0(\"Heart Disease Ratio Train: \", (train_m %&gt;% filter(heart_disease == 'Present') %&gt;% nrow())/ (train_m %&gt;% nrow())*100 ), \n  paste0(\"Heart Disease Ratio Test: \", (test_m %&gt;% filter(heart_disease == 'Present') %&gt;% nrow())/ (test_m %&gt;% nrow())*100 ),\" \", \" \",sep = \"\\n\")\n\nwomen_percent &lt;- paste(\"Women:\",\n  paste0(\"Heart Disease Ratio Train: \", (train_w %&gt;% filter(heart_disease == 'Present') %&gt;% nrow())/ (train_w %&gt;% nrow())*100 ), \n  paste0(\"Heart Disease Ratio Test: \", (test_w %&gt;% filter(heart_disease == 'Present') %&gt;% nrow())/ (test_w %&gt;% nrow())*100 ),\" \",sep = \"\\n\")\n\nprint(paste0( cat(men_percent)[1], cat(women_percent)[1]))\n\nMen:\nHeart Disease Ratio Train: 55.3191489361702\nHeart Disease Ratio Test: 56.6666666666667\n \n Women:\nHeart Disease Ratio Train: 22.0588235294118\nHeart Disease Ratio Test: 35.7142857142857\n character(0)\n\n\nIt is worth noting that women without heart disease in this dataset are represented MUCH lower rate than women with it.\nThis begs the question, are women less likely to have heart disease, are there not enough samples of women, or is it a combination of both?\n\nAlso note that the testing and training set containing both sexes is the combination of the the male and female training and testing sets. This way, when we compare the sex specific trees with the full tree, we know the full tree saw the same training data.\n\nWithout further ado, let’s grow our trees!\n\nfull_tree &lt;- rpart(heart_disease ~ ., data = train, method = \"class\")\nmale_tree &lt;- rpart(heart_disease ~ ., data = train_m, method = \"class\")\nfemale_tree &lt;- rpart(heart_disease ~ ., data = train_w, method = \"class\")"
  },
  {
    "objectID": "portfolio/projects/heartdisease.html#results-and-discussion",
    "href": "portfolio/projects/heartdisease.html#results-and-discussion",
    "title": "Heart Disease Indicators by Sex",
    "section": "Results and Discussion",
    "text": "Results and Discussion\nFinally, we get to see which features our decision trees chose as the most indicative of heart disease.\nLet’s start by taking a look at the full tree:\n\nrpart.plot(full_tree, main = \"Full Decision Tree (includes both sexes)\")\n\n\n\n\n\n\n\n\nAccording to our tree, the most important feature is cp (Chest Pain Type (integers 1 - 4) where categories 1 through 3 present symptoms, while 4 is asymptomatic):\n\nIf the patient does not have chest pain symptoms (cp == 4), then we take a look at ca (number of major vessels (0-3) colored by flourosopy) and thal (3 = normal; 6 = fixed defect; 7 = reversable defect ), and find the patient to be at risk of heart disease if they any number of major vessels colored by flourosopy or a non-normal thal.\nIf the patient does have chest pain symptoms (cp == 1, 2, or 3), then the patient is at risk of of heart disease if they are over 57, and a male with a cholesterol over 246.\n\nThis demonstrates the huge benefits of a decision tree, as both patients and medical professionals can clearly see from their own medical data where they lie.\nNow we will evaluate the accuracy as a whole, and for both sexes.\n\npredictions_full &lt;- predict(full_tree, test, type = \"class\")\n\ncm &lt;- confusionMatrix(predictions_full, as.factor(test$heart_disease))\nprint(paste0(\"Accuracy: \", cm$overall[1]))\n\n[1] \"Accuracy: 0.795454545454545\"\n\ncm$table\n\n          Reference\nPrediction None Present\n   None      39      13\n   Present    5      31\n\n# Add prediction to our test df\ntest$pred &lt;- predictions_full\n\n# Print out the number of individuals the model did not correctly predict with heart disease\nwomen_w_hd &lt;-test %&gt;% filter(sex == 'female', heart_disease == 'Present') %&gt;% nrow()\nmen_w_hd &lt;- test %&gt;% filter(sex == 'male', heart_disease == 'Present') %&gt;% nrow() \nkable(test %&gt;% filter(heart_disease == 'Present', pred == 'None') %&gt;% group_by(sex) %&gt;% summarize(num_disease_not_found = n()) %&gt;% mutate(number_disease_in_test = case_when(sex == 'female' ~women_w_hd,\n                                                                             T ~men_w_hd),\n                                                  percent_missed = num_disease_not_found / number_disease_in_test*100))\n\n\n\n\nsex\nnum_disease_not_found\nnumber_disease_in_test\npercent_missed\n\n\n\n\nfemale\n5\n10\n50.00000\n\n\nmale\n8\n34\n23.52941\n\n\n\n\n\nWe see that the tree is achieving an accuracy of almost 0.8 . Out of the people with heart disease 31 were correctly identified and 13 were very unfortunately not found. Of the 13 people the model missed, 8 were men and 5 were women.\n_The model failed to identify 50% of women with heart disease and 23.5% of men with heart disease__.\n\nSex Based Trees\nLet’s now take a look at what kind of decision trees we trained when we looked at male, and female data separately.\n\nrpart.plot(male_tree, main = \"Male Decision Tree\")\n\n\n\n\n\n\n\n\n\nrpart.plot(female_tree, main = \"Female Decision Tree\")\n\n\n\n\n\n\n\n\nImmediately the difference becomes evident. We can see that the male decision tree is almost identical to the full decision tree, with the replacement of thal with thalach (and of course removing the sex factor). But the female decision tree simply looks at one indicator for heart disease. Whether of not a woman has a non-normal thal is the sole indicator, which is an incredibly important detail that we cannot immediately gather from the full tree.\n\npredictions_male &lt;- predict(male_tree, test_m, type = \"class\")\ncm_m &lt;- confusionMatrix(predictions_male, as.factor(test_m$heart_disease))\nprint(paste0(\"Male Tree Accuracy: \", cm_m$overall[1]))\n\n[1] \"Male Tree Accuracy: 0.766666666666667\"\n\ncm_m$table\n\n          Reference\nPrediction None Present\n   None      22      10\n   Present    4      24\n\npredictions_female &lt;- predict(female_tree, test_w, type = \"class\")\ncm_w &lt;- confusionMatrix(predictions_female, as.factor(test_w$heart_disease))\nprint(paste0(\"Female Tree Accuracy: \", cm_w$overall[1]))\n\n[1] \"Female Tree Accuracy: 0.821428571428571\"\n\ncm_w$table\n\n          Reference\nPrediction None Present\n   None      17       4\n   Present    1       6\n\n# Add prediction to our test df\ntest_w$pred &lt;- predictions_female\ntest_m$pred &lt;- predictions_male\n\nInterestingly enough, the male tree accuracy is lower than the full tree (two additional individuals are incorrectly undiagnosed), but that the female tree accuracy is higher and does better at predicting heart disease."
  },
  {
    "objectID": "portfolio/projects/heartdisease.html#conclusion-and-future-work",
    "href": "portfolio/projects/heartdisease.html#conclusion-and-future-work",
    "title": "Heart Disease Indicators by Sex",
    "section": "Conclusion and Future Work",
    "text": "Conclusion and Future Work\nThrough a straightforward exploration of heart disease indicators based on sex, we can see (literally in our trees!) that male and female symptoms present differently. More importantly, the key indicators a doctor considers should vary based on the patient’s sex.\nTo ensure medical treatment is representative, it’s crucial to take steps to include women equally in medical studies and research. One approach is to ensure equal numbers of male and female participants in research. Another is to develop better accuracy metrics for predictive models that account for disproportionate representation within samples.\nThis dataset is both fascinating and promising, with ample opportunities for further analysis. Future work could include exploring other models, incorporating additional data sources, and fine-tuning parameters using cross-validation."
  },
  {
    "objectID": "portfolio/projects/heartdisease.html#references",
    "href": "portfolio/projects/heartdisease.html#references",
    "title": "Heart Disease Indicators by Sex",
    "section": "References",
    "text": "References\nCenters for Disease Control and Prevention. (2021, January 19). Heart disease. Centers for Disease Control and Prevention. Retrieved September 29, 2021, from https://www.cdc.gov/heartdisease/index.htm\nDoyal, L. (2001). Sex, gender, and health: The need for a new approach. BMJ, 323(7320), 1061–1063. https://doi.org/10.1136/bmj.323.7320.1061\nWeisz, D., Gusmano, M. K., & Rodwin, V. G. (2004). Gender and the treatment of heart disease in older persons in the United States, France, and England: A Comparative, Population-based view of a clinical phenomenon. Gender Medicine, 1(1), 29–40. https://doi.org/10.1016/s1550-8579(04)80008-1\nJanosi, A., Steinbrunn, W., Pfisterer, M., Detrano, R. (1988). Heart Disease Data Set, electronic dataset, UCI Machine Learning Repository. https://archive.ics.uci.edu/ml/datasets/Heart+Disease"
  },
  {
    "objectID": "portfolio/projects/reddit-LLM.html",
    "href": "portfolio/projects/reddit-LLM.html",
    "title": "A Computational Analysis of Hate Speech Across Reddit - Large Language Models",
    "section": "",
    "text": "The internet has become a breeding ground for various ideologies, some of which propagate harmful narratives and hate speech. One such community that has gained notoriety in the past decade is the “incel” (involuntary celibate) movement, known for its misogynistic rhetoric and, in some cases, calls for violence against women. The banning of the r/Incels subreddit in 2017 marked a significant moment in Reddit’s content moderation efforts, but it also led to the dispersion of this community across other platforms and other subreddits.\nThis project aims to leverage the power of Natural Language Processing (NLP) and Machine Learning (ML) techniques to track the evolution of incel-related hate speech and sentiment on Reddit. By focusing on the banned r/Incels subreddit and its subsequent offshoots, I seek to understand how misogynistic language persists and evolves in online spaces, even after community bans.\nBack in 2021 I conducted some analysis of this data. As you will see below, I leveraged Spark to ingest, and process Reddit posts, taking advantage of the then-free access to Reddit’s API. I then trained Large Language Models (LLMs) to classify the r/Incels subreddit posts, and applied this model to offshoots of this community post-ban, yielding interesting results.\nWith advancements in the NLP field, I wanted to revisit this 2021 project using some sentiment analysis techniques. I have just started working on this analysis, and you can follow my progress in the notebook here."
  },
  {
    "objectID": "portfolio/projects/reddit-LLM.html#data-cleaning",
    "href": "portfolio/projects/reddit-LLM.html#data-cleaning",
    "title": "A Computational Analysis of Hate Speech Across Reddit - Large Language Models",
    "section": "Data Cleaning",
    "text": "Data Cleaning\nThe first step (at the time) was to use Reddit’s Pushshift API to gather all r/incel historical posts. Using spark, I read in the data with the following code, and began to clean it:\n\nimport findspark\nfindspark.init()\n\nfrom sparknlp.annotator import *\nfrom sparknlp.base import *\nimport sparknlp\nfrom pyspark import SparkContext, SparkConf\nfrom pyspark.sql import SQLContext, SparkSession\nfrom pyspark.sql.functions import udf, col\nimport pyspark.sql.functions as F\nfrom pyspark.sql.types import IntegerType, StringType\nfrom pyspark.ml import Pipeline\nfrom sparknlp.pretrained import PretrainedPipeline\n\nimport pandas as pd\nimport numpy as np\nimport glob\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom sklearn.model_selection import train_test_split\n\n# Initialize Spark\nsparknlp.start()\nconf = SparkConf().setAppName('subreddit-classification')\nsc = SparkContext.getOrCreate()\nspark = SQLContext(sc)\n\n# Clean the data\ndf = df.withColumnRenamed('selftext', 'text')\n\ndf = df.select('subreddit', 'title')\n\ndf = df.filter(df.title != '[deleted]')\\\n               .filter(df.title != '[removed]')\\\n               .filter(df.title != '')\n\n# Label the data 1 if from r/incel and 0 if not\ndf_incel = df.withColumn(\n    'label',\n    F.when((F.col(\"subreddit\") == 'Incels') , '1')\\\n    .otherwise('0')\n)"
  },
  {
    "objectID": "portfolio/projects/reddit-LLM.html#training-llms-with-sparknlp",
    "href": "portfolio/projects/reddit-LLM.html#training-llms-with-sparknlp",
    "title": "A Computational Analysis of Hate Speech Across Reddit - Large Language Models",
    "section": "Training LLMs with SparkNLP",
    "text": "Training LLMs with SparkNLP\nI used SparkNLP to train two LLMs, one trained using submission titles, and another using submission post text. Submission post text provides us with the benefit of a lot more context and words than a title, however not all submissions contain usable post text.\n\n\n\nSparkNLP pipeline for subreddit classification\n\n\nAs seen in the pipeline graphic above and code below, I initialized the Document Assembler, Universal Sentence Encode, and Classifier DL for my LLM pipeline.\n\n# SparkNLP Pipeline\ndocument = DocumentAssembler()\\\n    .setInputCol(\"title\")\\\n    .setOutputCol(\"document\")\nprint(\"Document Done\")\n\nuse = UniversalSentenceEncoder.pretrained()\\\n .setInputCols([\"document\"])\\\n .setOutputCol(\"sentence_embeddings\")\nprint(\"Use Done\")\n\nclasssifierdl = ClassifierDLApproach().setInputCols([\"sentence_embeddings\"])\\\n    .setOutputCol(\"class\")\\\n    .setLabelColumn(\"label\")\\\n    .setMaxEpochs(10)\\\n    .setEnableOutputLogs(True)\\\n    .setLr(0.004)\nprint(\"Classifierd Done\")\n\nnlpPipeline = Pipeline(       \n    stages = [\n        document,\n        use,\n        classsifierdl\n    ])\n\n\n\n\nModel Stats for two models: one trained using submission titles, and one using submission post text\n\n\nThe next step was to split the data into testing and training sets, and train the model. Performing this once using submission titles and again using submission post text I found that the posts model was slightly more accurate. The training data and accuracy, precision, and recall for both models can be seen in the table above.\nWhile the accuracy is slightly better for the model trained on post text, the number of submissions the model was trained on was significantly lower (10,000 submissions vs. 2,000). This is because, after the cleaning process for the post text model, only 2,000 submissions remained. The implication is that this model, while it performs better, is less applicable as it cannot be used on 80% of the submissions. Therefore, going forward, I recommend using the model trained on submission titles.\nBelow is the code to train the title model:\n\n# Split into test and training set\n(train_set, test_set)= df_incel.randomSplit([0.8, 0.2], seed=100)\n\n\n# Train the model\nmodel_incel = nlpPipeline.fit(train_set)\n\n# Predict Testing Data\ndf_incel= model_incel.transform(test_set).select(\"subreddit\", \"title\",\"label\", \"document\", \"class.result\").toPandas()\ndf_incel[\"result\"] = df_incel[\"result\"].apply(lambda x:x[0])"
  },
  {
    "objectID": "resume/index.html",
    "href": "resume/index.html",
    "title": "Resume",
    "section": "",
    "text": "Download current Resume"
  },
  {
    "objectID": "portfolio/index 2.html",
    "href": "portfolio/index 2.html",
    "title": "Projects",
    "section": "",
    "text": "A Computational Analysis of Hate Speech Across Reddit - Large Language Models\n\n\n\n\n\n\nPython\n\n\nML\n\n\nNLP\n\n\nLLM\n\n\n\n\n\n\n\n\n\nJul 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nGeologic Magmatic Migration Exploration Through Age Prediction\n\n\n\n\n\n\nPython\n\n\nGIS\n\n\nShiny\n\n\nEDA\n\n\nML\n\n\n\nDevelopping novel ML methods for magamtic migration predictions\n\n\n\n\n\nJul 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHeart Disease Indicators by Sex\n\n\n\n\n\n\nEDA\n\n\nHealthcare\n\n\nR\n\n\nML\n\n\n\n\n\n\n\n\n\nJul 18, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "portfolio/projects/heartdisease 2.html",
    "href": "portfolio/projects/heartdisease 2.html",
    "title": "Heart Disease Indicators by Sex",
    "section": "",
    "text": "Heart disease is a leading cause of mortality worldwide, yet significant gender disparities exist in its study and treatment. Historically, research has predominantly focused on male patients, resulting in diagnostic and treatment protocols that do not fully address the unique ways in which heart disease manifests in women. This oversight has led to a critical gap in our understanding and care of heart disease in women.\nThe original data can me found here. I have already saved it as a csv file and will be accessing this file. Mutliple researchers have explored this data and gotten good predictions on the data!\nThe goal of this project is to explore how sex plays a role in heart disease indicators. By doing so, we aim to provide medical professionals with deeper insights into the early indicators of heart disease and ensure that sex-specific factors are considered for improved diagnosis and treatment.\nTo get started lets read in the data and take a look at the first 5 rows.\n\npackages &lt;- c(\"tidyr\", \"readxl\", \"dplyr\", \"magrittr\", \"purrr\", \n              \"ggplot2\", \"stringr\", \"snakecase\", \"knitr\", \"caret\",\n              \"rpart\", \"rpart.plot\") \ninvisible(lapply(packages, require, character.only = TRUE ))\n\n\ndf_raw &lt;- read.csv(\"data/heart_disease.csv\")\nkable(df_raw[1:5,], caption = \"Raw Data\")\n\n\nRaw Data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nage\nsex\ncp\ntrestbps\nchol\nfbs\nrestecg\nthalach\nexang\noldpeak\nslope\nca\nthal\nnum\n\n\n\n\n63\n1\n1\n145\n233\n1\n2\n150\n0\n2.3\n3\n0\n6\n0\n\n\n67\n1\n4\n160\n286\n0\n2\n108\n1\n1.5\n2\n3\n3\n2\n\n\n67\n1\n4\n120\n229\n0\n2\n129\n1\n2.6\n2\n2\n7\n1\n\n\n37\n1\n3\n130\n250\n0\n0\n187\n0\n3.5\n3\n0\n3\n0\n\n\n41\n0\n2\n130\n204\n0\n2\n172\n0\n1.4\n1\n0\n3\n0\n\n\n\n\nna_cols &lt;- names(which(colSums(is.na(df_raw)) &gt; 0))\nprint(na_cols)\n\n[1] \"ca\"   \"thal\"\n\n\nThe data consists of 14 columns, including num which is our heart disease number. Two of these columns have NA values: ca and thal. Lets clean up the data and start exploring what we have."
  },
  {
    "objectID": "portfolio/projects/heartdisease 2.html#introduction",
    "href": "portfolio/projects/heartdisease 2.html#introduction",
    "title": "Heart Disease Indicators by Sex",
    "section": "",
    "text": "Heart disease is a leading cause of mortality worldwide, yet significant gender disparities exist in its study and treatment. Historically, research has predominantly focused on male patients, resulting in diagnostic and treatment protocols that do not fully address the unique ways in which heart disease manifests in women. This oversight has led to a critical gap in our understanding and care of heart disease in women.\nThe original data can me found here. I have already saved it as a csv file and will be accessing this file. Mutliple researchers have explored this data and gotten good predictions on the data!\nThe goal of this project is to explore how sex plays a role in heart disease indicators. By doing so, we aim to provide medical professionals with deeper insights into the early indicators of heart disease and ensure that sex-specific factors are considered for improved diagnosis and treatment.\nTo get started lets read in the data and take a look at the first 5 rows.\n\npackages &lt;- c(\"tidyr\", \"readxl\", \"dplyr\", \"magrittr\", \"purrr\", \n              \"ggplot2\", \"stringr\", \"snakecase\", \"knitr\", \"caret\",\n              \"rpart\", \"rpart.plot\") \ninvisible(lapply(packages, require, character.only = TRUE ))\n\n\ndf_raw &lt;- read.csv(\"data/heart_disease.csv\")\nkable(df_raw[1:5,], caption = \"Raw Data\")\n\n\nRaw Data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nage\nsex\ncp\ntrestbps\nchol\nfbs\nrestecg\nthalach\nexang\noldpeak\nslope\nca\nthal\nnum\n\n\n\n\n63\n1\n1\n145\n233\n1\n2\n150\n0\n2.3\n3\n0\n6\n0\n\n\n67\n1\n4\n160\n286\n0\n2\n108\n1\n1.5\n2\n3\n3\n2\n\n\n67\n1\n4\n120\n229\n0\n2\n129\n1\n2.6\n2\n2\n7\n1\n\n\n37\n1\n3\n130\n250\n0\n0\n187\n0\n3.5\n3\n0\n3\n0\n\n\n41\n0\n2\n130\n204\n0\n2\n172\n0\n1.4\n1\n0\n3\n0\n\n\n\n\nna_cols &lt;- names(which(colSums(is.na(df_raw)) &gt; 0))\nprint(na_cols)\n\n[1] \"ca\"   \"thal\"\n\n\nThe data consists of 14 columns, including num which is our heart disease number. Two of these columns have NA values: ca and thal. Lets clean up the data and start exploring what we have."
  },
  {
    "objectID": "portfolio/projects/heartdisease 2.html#data-cleaning-and-initial-observations",
    "href": "portfolio/projects/heartdisease 2.html#data-cleaning-and-initial-observations",
    "title": "Heart Disease Indicators by Sex",
    "section": "Data Cleaning and Initial Observations",
    "text": "Data Cleaning and Initial Observations\nFirst, let’s label the data in an easier way to understand for num (heart disease), and sex.\n\n# Add yes/no heart disease column\n# Label sex as male/female for convenience\ndf &lt;- df_raw %&gt;% \n  mutate( heart_disease = case_when(\n    num == 0 ~\"None\", T ~\"Present\"),\n    sex = case_when(sex==1 ~\"male\", T ~\"female\"))\n\n# View data with NA values\nkable(df %&gt;% filter(if_any(everything(), is.na)))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nage\nsex\ncp\ntrestbps\nchol\nfbs\nrestecg\nthalach\nexang\noldpeak\nslope\nca\nthal\nnum\nheart_disease\n\n\n\n\n53\nfemale\n3\n128\n216\n0\n2\n115\n0\n0.0\n1\n0\nNA\n0\nNone\n\n\n52\nmale\n3\n138\n223\n0\n0\n169\n0\n0.0\n1\nNA\n3\n0\nNone\n\n\n43\nmale\n4\n132\n247\n1\n2\n143\n1\n0.1\n2\nNA\n7\n1\nPresent\n\n\n52\nmale\n4\n128\n204\n1\n0\n156\n1\n1.0\n2\n0\nNA\n2\nPresent\n\n\n58\nmale\n2\n125\n220\n0\n0\n144\n0\n0.4\n2\nNA\n7\n0\nNone\n\n\n38\nmale\n3\n138\n175\n0\n0\n173\n0\n0.0\n1\nNA\n3\n0\nNone\n\n\n\n\n# Remove NAs\ndf %&lt;&gt;% drop_na()\n\n# Plot heart disease vs. no disease \nggplot(df, aes(x = heart_disease, fill = sex))+\n  geom_bar(position = position_dodge())+\n  ggtitle(\"Count of Detected Heart Disease for Women and Men\")+xlab(\"Heart Disease\")\n\n\n\n\n\n\n\n# Sex split in the data\nprint(paste0(\"Number of women: \", df %&gt;% filter(sex == 'female') %&gt;% nrow(),\"   \",\n             \"Number of men: \", df %&gt;% filter(sex == 'male') %&gt;% nrow()))\n\n[1] \"Number of women: 96   Number of men: 201\"\n\n# Heart Disease numbers by sex\nmen &lt;- paste0(\"Men with HD:  \", df %&gt;% filter(sex == 'male', heart_disease == 'Present') %&gt;% nrow())\nwomen &lt;- paste0(\"Women with HD:  \", df %&gt;% filter(sex == 'female', heart_disease == 'Present') %&gt;% nrow())\nstats_to_print &lt;- paste(men, women, sep = \"\\n\")\n\ncat(stats_to_print[1])\n\nMen with HD:  112\nWomen with HD:  25\n\n\n\nnormalize &lt;- function(x) {\n  return ((x - min(x)) / (max(x) - min(x)))\n}\n\n# Plot avg across all features for men and women\ndf %&gt;% select(-num) %&gt;% mutate_at(vars(-sex, -heart_disease), normalize)%&gt;% \n  group_by(sex, heart_disease) %&gt;%  summarise_all(mean) %&gt;%  ungroup() %&gt;% \n  pivot_longer(cols= !c(\"sex\", \"heart_disease\"), names_to = 'feature', values_to = 'mean') %&gt;% \n  ggplot()+\n  geom_point(aes(x = feature, y = mean, color = sex))+coord_flip()+facet_wrap(.~heart_disease)+ xlab(\"\")+ylab(\"Normalized Mean\")+\n  ggtitle(\"Feature Means Split By Heart Disease Present vs. None\")\n\n\n\n\n\n\n\n\nDuring the data cleaning process, six data points were removed due to missing information. While imputation methods could be considered to address this issue, for the purpose of this project, I have chosen to omit this step. The primary goal here is to understand the impact of sex on predicting heart disease, rather than achieving the highest possible prediction accuracy.\nAn initial review of the dataset reveals a significant gender imbalance, with more men represented in the study than women. This is true for both individuals diagnosed with heart disease and those without. The graph of feature means illustrates differences between feature expression for those with and without heart disease. Additionally, certain features, such as thal, oldpeak, and exang, display distinct variations between men and women. This suggests that the same approach to finding heart disease indicators may not be equally effective for both men and women."
  },
  {
    "objectID": "portfolio/projects/heartdisease 2.html#decision-tree-models",
    "href": "portfolio/projects/heartdisease 2.html#decision-tree-models",
    "title": "Heart Disease Indicators by Sex",
    "section": "Decision Tree Models",
    "text": "Decision Tree Models\nBringing it back to our original goal, to explore how sex plays a role in heart disease indicators, I am going to look at a series of decision trees.\n\nWhy Decision Trees?\nDecision trees may not always be the best models that give the highest predictive accuracy, however I think are a great model to use to help us understand our problem at hand.\nDecision trees are easy to understand and interpret, making the logic behind the predictions clear. This transparency is particularly valuable in the medical field, where it is crucial to explain why certain features are indicative of heart disease. Unlike more complex models such as neural networks, decision trees do not require dimensionality reduction, and they can directly use the original features of the dataset. This simplicity helps maintain the medical terminology and context, making the results more accessible and actionable for healthcare professionals.\n\n\nBuilding the Models\nTo understand how women and men are represented within the model, lets build three decision trees:\n\nFull Tree: This tree will be built using the training set from all the data.\nMale Tree: This tree will be built using the training set from the data filtered to sex == 'male'.\nFemale Tree: This tree will be built using the training set from the data filtered to sex == 'female'\n\nAll trees will use a 70/30 training/test split, and use the gini index within the tree.\n\nI will not be performing any hyper-parameter tuning in this project. Please take a look at a one of my more in-depth project, such as this one, if you are interested in this.\n\n\n# Set seed for reproducebility\nset.seed(1)\n\n# Remove num \ndf %&lt;&gt;% select(-num) \n\n# Split the data into test/train sets\n#### Men\ndf_m &lt;- df %&gt;% filter(sex == 'male')\nidx_m &lt;- createDataPartition(df_m$sex,p=0.7,list=FALSE)\ntrain_m &lt;- df_m[idx_m, ]\ntest_m &lt;- df_m[-idx_m, ]\n\n#### Women\ndf_w &lt;- df %&gt;% filter(sex == 'female')\nidx_w &lt;- createDataPartition(df_w$sex,p=0.7,list=FALSE)\ntrain_w &lt;- df_w[idx_w, ]\ntest_w &lt;- df_w[-idx_w, ]\n\ntrain &lt;- rbind(train_m, train_w)\ntest &lt;- rbind(test_m, test_w)\n\n# Percent of heart disease in train and test\nmen_percent &lt;- paste(\"Men:\",\n  paste0(\"Heart Disease Ratio Train: \", (train_m %&gt;% filter(heart_disease == 'Present') %&gt;% nrow())/ (train_m %&gt;% nrow())*100 ), \n  paste0(\"Heart Disease Ratio Test: \", (test_m %&gt;% filter(heart_disease == 'Present') %&gt;% nrow())/ (test_m %&gt;% nrow())*100 ),\" \", \" \",sep = \"\\n\")\n\nwomen_percent &lt;- paste(\"Women:\",\n  paste0(\"Heart Disease Ratio Train: \", (train_w %&gt;% filter(heart_disease == 'Present') %&gt;% nrow())/ (train_w %&gt;% nrow())*100 ), \n  paste0(\"Heart Disease Ratio Test: \", (test_w %&gt;% filter(heart_disease == 'Present') %&gt;% nrow())/ (test_w %&gt;% nrow())*100 ),\" \",sep = \"\\n\")\n\nprint(paste0( cat(men_percent)[1], cat(women_percent)[1]))\n\nMen:\nHeart Disease Ratio Train: 55.3191489361702\nHeart Disease Ratio Test: 56.6666666666667\n \n Women:\nHeart Disease Ratio Train: 22.0588235294118\nHeart Disease Ratio Test: 35.7142857142857\n character(0)\n\n\nIt is worth noting that women without heart disease in this dataset are represented MUCH lower rate than women with it.\nThis begs the question, are women less likely to have heart disease, are there not enough samples of women, or is it a combination of both?\n\nAlso note that the testing and training set containing both sexes is the combination of the the male and female training and testing sets. This way, when we compare the sex specific trees with the full tree, we know the full tree saw the same training data.\n\nWithout further ado, let’s grow our trees!\n\nfull_tree &lt;- rpart(heart_disease ~ ., data = train, method = \"class\")\nmale_tree &lt;- rpart(heart_disease ~ ., data = train_m, method = \"class\")\nfemale_tree &lt;- rpart(heart_disease ~ ., data = train_w, method = \"class\")"
  },
  {
    "objectID": "portfolio/projects/heartdisease 2.html#results-and-discussion",
    "href": "portfolio/projects/heartdisease 2.html#results-and-discussion",
    "title": "Heart Disease Indicators by Sex",
    "section": "Results and Discussion",
    "text": "Results and Discussion\nFinally, we get to see which features our decision trees chose as the most indicative of heart disease.\nLet’s start by taking a look at the full tree:\n\nrpart.plot(full_tree, main = \"Full Decision Tree (includes both sexes)\")\n\n\n\n\n\n\n\n\nAccording to our tree, the most important feature is cp (Chest Pain Type (integers 1 - 4) where categories 1 through 3 present symptoms, while 4 is asymptomatic):\n\nIf the patient does not have chest pain symptoms (cp == 4), then we take a look at ca (number of major vessels (0-3) colored by flourosopy) and thal (3 = normal; 6 = fixed defect; 7 = reversable defect ), and find the patient to be at risk of heart disease if they any number of major vessels colored by flourosopy or a non-normal thal.\nIf the patient does have chest pain symptoms (cp == 1, 2, or 3), then the patient is at risk of of heart disease if they are over 57, and a male with a cholesterol over 246.\n\nThis demonstrates the huge benefits of a decision tree, as both patients and medical professionals can clearly see from their own medical data where they lie.\nNow we will evaluate the accuracy as a whole, and for both sexes.\n\npredictions_full &lt;- predict(full_tree, test, type = \"class\")\n\ncm &lt;- confusionMatrix(predictions_full, as.factor(test$heart_disease))\nprint(paste0(\"Accuracy: \", cm$overall[1]))\n\n[1] \"Accuracy: 0.795454545454545\"\n\ncm$table\n\n          Reference\nPrediction None Present\n   None      39      13\n   Present    5      31\n\n# Add prediction to our test df\ntest$pred &lt;- predictions_full\n\n# Print out the number of individuals the model did not correctly predict with heart disease\nwomen_w_hd &lt;-test %&gt;% filter(sex == 'female', heart_disease == 'Present') %&gt;% nrow()\nmen_w_hd &lt;- test %&gt;% filter(sex == 'male', heart_disease == 'Present') %&gt;% nrow() \nkable(test %&gt;% filter(heart_disease == 'Present', pred == 'None') %&gt;% group_by(sex) %&gt;% summarize(num_disease_not_found = n()) %&gt;% mutate(number_disease_in_test = case_when(sex == 'female' ~women_w_hd,\n                                                                             T ~men_w_hd),\n                                                  percent_missed = num_disease_not_found / number_disease_in_test*100))\n\n\n\n\nsex\nnum_disease_not_found\nnumber_disease_in_test\npercent_missed\n\n\n\n\nfemale\n5\n10\n50.00000\n\n\nmale\n8\n34\n23.52941\n\n\n\n\n\nWe see that the tree is achieving an accuracy of almost 0.8 . Out of the people with heart disease 31 were correctly identified and 13 were very unfortunately not found. Of the 13 people the model missed, 8 were men and 5 were women.\n_The model failed to identify 50% of women with heart disease and 23.5% of men with heart disease__.\n\nSex Based Trees\nLet’s now take a look at what kind of decision trees we trained when we looked at male, and female data separately.\n\nrpart.plot(male_tree, main = \"Male Decision Tree\")\n\n\n\n\n\n\n\n\n\nrpart.plot(female_tree, main = \"Female Decision Tree\")\n\n\n\n\n\n\n\n\nImmediately the difference becomes evident. We can see that the male decision tree is almost identical to the full decision tree, with the replacement of thal with thalach (and of course removing the sex factor). But the female decision tree simply looks at one indicator for heart disease. Whether of not a woman has a non-normal thal is the sole indicator, which is an incredibly important detail that we cannot immediately gather from the full tree.\n\npredictions_male &lt;- predict(male_tree, test_m, type = \"class\")\ncm_m &lt;- confusionMatrix(predictions_male, as.factor(test_m$heart_disease))\nprint(paste0(\"Male Tree Accuracy: \", cm_m$overall[1]))\n\n[1] \"Male Tree Accuracy: 0.766666666666667\"\n\ncm_m$table\n\n          Reference\nPrediction None Present\n   None      22      10\n   Present    4      24\n\npredictions_female &lt;- predict(female_tree, test_w, type = \"class\")\ncm_w &lt;- confusionMatrix(predictions_female, as.factor(test_w$heart_disease))\nprint(paste0(\"Female Tree Accuracy: \", cm_w$overall[1]))\n\n[1] \"Female Tree Accuracy: 0.821428571428571\"\n\ncm_w$table\n\n          Reference\nPrediction None Present\n   None      17       4\n   Present    1       6\n\n# Add prediction to our test df\ntest_w$pred &lt;- predictions_female\ntest_m$pred &lt;- predictions_male\n\nInterestingly enough, the male tree accuracy is lower than the full tree (two additional individuals are incorrectly undiagnosed), but that the female tree accuracy is higher and does better at predicting heart disease."
  },
  {
    "objectID": "portfolio/projects/heartdisease 2.html#conclusion-and-future-work",
    "href": "portfolio/projects/heartdisease 2.html#conclusion-and-future-work",
    "title": "Heart Disease Indicators by Sex",
    "section": "Conclusion and Future Work",
    "text": "Conclusion and Future Work\nThrough a straightforward exploration of heart disease indicators based on sex, we can see (literally in our trees!) that male and female symptoms present differently. More importantly, the key indicators a doctor considers should vary based on the patient’s sex.\nTo ensure medical treatment is representative, it’s crucial to take steps to include women equally in medical studies and research. One approach is to ensure equal numbers of male and female participants in research. Another is to develop better accuracy metrics for predictive models that account for disproportionate representation within samples.\nThis dataset is both fascinating and promising, with ample opportunities for further analysis. Future work could include exploring other models, incorporating additional data sources, and fine-tuning parameters using cross-validation."
  },
  {
    "objectID": "portfolio/projects/heartdisease 2.html#references",
    "href": "portfolio/projects/heartdisease 2.html#references",
    "title": "Heart Disease Indicators by Sex",
    "section": "References",
    "text": "References\nCenters for Disease Control and Prevention. (2021, January 19). Heart disease. Centers for Disease Control and Prevention. Retrieved September 29, 2021, from https://www.cdc.gov/heartdisease/index.htm\nDoyal, L. (2001). Sex, gender, and health: The need for a new approach. BMJ, 323(7320), 1061–1063. https://doi.org/10.1136/bmj.323.7320.1061\nWeisz, D., Gusmano, M. K., & Rodwin, V. G. (2004). Gender and the treatment of heart disease in older persons in the United States, France, and England: A Comparative, Population-based view of a clinical phenomenon. Gender Medicine, 1(1), 29–40. https://doi.org/10.1016/s1550-8579(04)80008-1\nJanosi, A., Steinbrunn, W., Pfisterer, M., Detrano, R. (1988). Heart Disease Data Set, electronic dataset, UCI Machine Learning Repository. https://archive.ics.uci.edu/ml/datasets/Heart+Disease"
  },
  {
    "objectID": "README 2.html",
    "href": "README 2.html",
    "title": "Portfolio",
    "section": "",
    "text": "Portfolio\nRepo containing quarto site for my portfolio: https://lilynorthcutt.github.io/portfolio/"
  },
  {
    "objectID": "portfolio/projects/reddit-LLM 2.html",
    "href": "portfolio/projects/reddit-LLM 2.html",
    "title": "A Computational Analysis of Hate Speech Across Reddit - Large Language Models",
    "section": "",
    "text": "The internet has become a breeding ground for various ideologies, some of which propagate harmful narratives and hate speech. One such community that has gained notoriety in the past decade is the “incel” (involuntary celibate) movement, known for its misogynistic rhetoric and, in some cases, calls for violence against women. The banning of the r/Incels subreddit in 2017 marked a significant moment in Reddit’s content moderation efforts, but it also led to the dispersion of this community across other platforms and other subreddits.\nThis project aims to leverage the power of Natural Language Processing (NLP) and Machine Learning (ML) techniques to track the evolution of incel-related hate speech and sentiment on Reddit. By focusing on the banned r/Incels subreddit and its subsequent offshoots, we seek to understand how misogynistic language persists and evolves in online spaces, even after community bans.\nBack in 2021 I conducted some analysis of this data. As you will see below, I leveraged Spark to ingest, and process Reddit posts, taking advantage of the then-free access to Reddit’s API. I then trained Large Language Models (LLMs) to classify the r/Incels subreddit posts, and applied this model to offshoots of this community post-ban, yielding interesting results.\nWith advancements in the NLP field, I wanted to revisit this 2021 project using some sentiment analysis techniques. This analysis can be found in a different notebook here."
  },
  {
    "objectID": "portfolio/projects/reddit-LLM 2.html#data-cleaning",
    "href": "portfolio/projects/reddit-LLM 2.html#data-cleaning",
    "title": "A Computational Analysis of Hate Speech Across Reddit - Large Language Models",
    "section": "Data Cleaning",
    "text": "Data Cleaning\nThe first step (at the time) was to use Reddit’s Pushshift API to gather all r/incel historical posts. Using spark, I read in the data with the following code, and began to clean it:\n\nimport findspark\nfindspark.init()\n\nfrom sparknlp.annotator import *\nfrom sparknlp.base import *\nimport sparknlp\nfrom pyspark import SparkContext, SparkConf\nfrom pyspark.sql import SQLContext, SparkSession\nfrom pyspark.sql.functions import udf, col\nimport pyspark.sql.functions as F\nfrom pyspark.sql.types import IntegerType, StringType\nfrom pyspark.ml import Pipeline\nfrom sparknlp.pretrained import PretrainedPipeline\n\nimport pandas as pd\nimport numpy as np\nimport glob\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom sklearn.model_selection import train_test_split\n\n# Initialize Spark\nsparknlp.start()\nconf = SparkConf().setAppName('subreddit-classification')\nsc = SparkContext.getOrCreate()\nspark = SQLContext(sc)\n\n# Clean the data\ndf = df.withColumnRenamed('selftext', 'text')\n\ndf = df.select('subreddit', 'title')\n\ndf = df.filter(df.title != '[deleted]')\\\n               .filter(df.title != '[removed]')\\\n               .filter(df.title != '')\n\n# Label the data 1 if from r/incel and 0 if not\ndf_incel = df.withColumn(\n    'label',\n    F.when((F.col(\"subreddit\") == 'Incels') , '1')\\\n    .otherwise('0')\n)"
  },
  {
    "objectID": "portfolio/projects/reddit-LLM 2.html#training-llms-with-sparknlp",
    "href": "portfolio/projects/reddit-LLM 2.html#training-llms-with-sparknlp",
    "title": "A Computational Analysis of Hate Speech Across Reddit - Large Language Models",
    "section": "Training LLMs with SparkNLP",
    "text": "Training LLMs with SparkNLP\nI used SparkNLP to train two LLMs, one trained using submission titles, and another using submission post text. Submission post text provides us with the benefit of a lot more context and words than a title, however not all submissions contain usable post text.\n\n\n\nSparkNLP pipeline for subreddit classification\n\n\nAs seen in the pipeline graphic above and code below, I initialized the Document Assembler, Universal Sentence Encode, and Classifier DL for my LLM pipeline.\n\n# SparkNLP Pipeline\ndocument = DocumentAssembler()\\\n    .setInputCol(\"title\")\\\n    .setOutputCol(\"document\")\nprint(\"Document Done\")\n\nuse = UniversalSentenceEncoder.pretrained()\\\n .setInputCols([\"document\"])\\\n .setOutputCol(\"sentence_embeddings\")\nprint(\"Use Done\")\n\nclasssifierdl = ClassifierDLApproach().setInputCols([\"sentence_embeddings\"])\\\n    .setOutputCol(\"class\")\\\n    .setLabelColumn(\"label\")\\\n    .setMaxEpochs(10)\\\n    .setEnableOutputLogs(True)\\\n    .setLr(0.004)\nprint(\"Classifierd Done\")\n\nnlpPipeline = Pipeline(       \n    stages = [\n        document,\n        use,\n        classsifierdl\n    ])\n\n\n\n\nModel Stats for two models: one trained using submission titles, and one using submission post text\n\n\nThe next step was to split the data into testing and training sets, and train the model. Performing this once using submission titles and again using submission post text I found that the posts model was slightly more accurate. The training data and accuracy, precision, and recall for both models can be seen in the table above.\nWhile the accuracy is slightly better for the model trained on post text, the number of submissions the model was trained on was significantly lower (10,000 submissions vs. 2,000). This is because, after the cleaning process for the post text model, only 2,000 submissions remained. The implication is that this model, while it performs better, is less applicable as it cannot be used on 80% of the submissions. Therefore, going forward, I recommend using the model trained on submission titles.\nBelow is the code to train the title model:\n\n# Split into test and training set\n(train_set, test_set)= df_incel.randomSplit([0.8, 0.2], seed=100)\n\n\n# Train the model\nmodel_incel = nlpPipeline.fit(train_set)\n\n# Predict Testing Data\ndf_incel= model_incel.transform(test_set).select(\"subreddit\", \"title\",\"label\", \"document\", \"class.result\").toPandas()\ndf_incel[\"result\"] = df_incel[\"result\"].apply(lambda x:x[0])"
  }
]